{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Fetching Data from Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 13:37:14,533:INFO - HTTP Request: GET https://supabase.cloud-atlas.xyz/rest/v1/_acceptance?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-11-21 13:37:14,545:INFO - HTTP Request: GET https://supabase.cloud-atlas.xyz/rest/v1/_actions?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-11-21 13:37:14,555:INFO - HTTP Request: GET https://supabase.cloud-atlas.xyz/rest/v1/_app_names?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-11-21 13:37:14,568:INFO - HTTP Request: GET https://supabase.cloud-atlas.xyz/rest/v1/_place_types?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-11-21 13:37:14,584:INFO - HTTP Request: GET https://supabase.cloud-atlas.xyz/rest/v1/_rel_user_location_place_types?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-11-21 13:37:14,596:INFO - HTTP Request: GET https://supabase.cloud-atlas.xyz/rest/v1/_sex?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-11-21 13:37:14,608:INFO - HTTP Request: GET https://supabase.cloud-atlas.xyz/rest/v1/user_app_usage?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-11-21 13:37:14,621:INFO - HTTP Request: GET https://supabase.cloud-atlas.xyz/rest/v1/user_behavior?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-11-21 13:37:14,633:INFO - HTTP Request: GET https://supabase.cloud-atlas.xyz/rest/v1/user_location?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-11-21 13:37:14,645:INFO - HTTP Request: GET https://supabase.cloud-atlas.xyz/rest/v1/users?select=%2A \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from supabase import create_client, Client\n",
    "import pandas as pd\n",
    "import os as os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Supabase client\n",
    "url: str = os.environ.get(\"SUPABASE_PUBLIC_URL\")\n",
    "key: str = os.environ.get(\"SUPABASE_SERVICE_ROLE_KEY\")\n",
    "supabase: Client = create_client(url, key)\n",
    "\n",
    "# Fetch data from each table\n",
    "_acceptance_data = supabase.table(\"_acceptance\").select(\"*\").execute().data\n",
    "_actions_data = supabase.table(\"_actions\").select(\"*\").execute().data\n",
    "_app_names_data = supabase.table(\"_app_names\").select(\"*\").execute().data\n",
    "_place_types = supabase.table(\"_place_types\").select(\"*\").execute().data\n",
    "_rel_user_location_place_types_data = supabase.table(\"_rel_user_location_place_types\").select(\"*\").execute().data\n",
    "_sex = supabase.table(\"_sex\").select(\"*\").execute().data\n",
    "\n",
    "user_app_usage_data = supabase.table(\"user_app_usage\").select(\"*\").execute().data\n",
    "user_behavior_data = supabase.table(\"user_behavior\").select(\"*\").execute().data\n",
    "user_location_data = supabase.table(\"user_location\").select(\"*\").execute().data\n",
    "users_data = supabase.table(\"users\").select(\"*\").execute().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>workplace</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-19T16:00:21.232935+00:00</td>\n",
       "      <td>f7427faa-c131-402a-9578-b742aaf3b5bd</td>\n",
       "      <td>2023-11-19T10:01:01+00:00</td>\n",
       "      <td>2023-11-19T12:02:02+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        created_at                               user_id  \\\n",
       "0   1  2023-11-19T16:00:21.232935+00:00  f7427faa-c131-402a-9578-b742aaf3b5bd   \n",
       "\n",
       "                  start_time                   end_time  workplace  home  \n",
       "0  2023-11-19T10:01:01+00:00  2023-11-19T12:02:02+00:00      False  True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to pandas DataFrames\n",
    "df__acceptance = pd.DataFrame(_acceptance_data)\n",
    "df__actions = pd.DataFrame(_actions_data)\n",
    "df__app_names = pd.DataFrame(_app_names_data)\n",
    "df__place_types = pd.DataFrame(_place_types)\n",
    "df__rel_user_location_place_types = pd.DataFrame(_rel_user_location_place_types_data)\n",
    "df__sex = pd.DataFrame(_sex)\n",
    "\n",
    "df_user_app_usage = pd.DataFrame(user_app_usage_data)\n",
    "df_user_behavior = pd.DataFrame(user_behavior_data)\n",
    "df_user_location = pd.DataFrame(user_location_data)\n",
    "df_users = pd.DataFrame(users_data)\n",
    "\n",
    "# Verify the structure of the dataframes\n",
    "df_user_location.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2 Data Preprocessing\n",
    "\n",
    "## 2.1 Calculate/simplify data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Start functions\n",
    "\n",
    "def convert_boolean_to_numeric(df_original, column_name):\n",
    "    \"\"\"\n",
    "    Converts a boolean column in a DataFrame to 0 or 1.\n",
    "    \"\"\"\n",
    "    df = df_original.copy()\n",
    "\n",
    "    # Convert boolean to int (True to 1, False to 0)\n",
    "    df[column_name] = df[column_name].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_string_to_date(df_original, dob_column):\n",
    "    \"\"\"\n",
    "    Converts a date of birth column from string to datetime and calculates the age.\n",
    "    \"\"\"\n",
    "    df = df_original.copy()\n",
    "    df[dob_column] = pd.to_datetime(df[dob_column])\n",
    "    df['age'] = df[dob_column].apply(\n",
    "        lambda dob: datetime.now().year - dob.year - ((datetime.now().month, datetime.now().day) < (dob.month, dob.day))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_duration_and_drop_end_time(df_original, start_time_col='start_time', end_time_col='end_time'):\n",
    "    \"\"\"\n",
    "    Calculates the duration in seconds between start and end times, and drops the end time column.\n",
    "    \"\"\"\n",
    "    df = df_original.copy()\n",
    "    df['duration'] = df.apply(\n",
    "        lambda row: (pd.to_datetime(row[end_time_col]).tz_convert('UTC') - pd.to_datetime(row[start_time_col]).tz_convert('UTC')).total_seconds(),\n",
    "        axis=1\n",
    "    )\n",
    "    df.drop(end_time_col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Final functions\n",
    "\n",
    "def normalize_numerical_data(df_original, column, fixed_max):\n",
    "    \"\"\"\n",
    "    Normalizes a specified column of the DataFrame.\n",
    "    \"\"\"\n",
    "    df = df_original.copy()\n",
    "\n",
    "    # Normalize the column\n",
    "    df[column] = df[column] / fixed_max\n",
    "    \n",
    "    # Ensure that the values do not exceed 1, more than 1 are clipped to 1\n",
    "    df[column] = df[column].clip(lower=0, upper=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_datetimez_data(df_original, column, fixed_min, fixed_max):\n",
    "    \"\"\"\n",
    "    Normalizes a specified datetime column of the DataFrame to a value between 0 and 1.\n",
    "    \"\"\"\n",
    "    df = df_original.copy()\n",
    "\n",
    "    # Convert datetime to numerical (timestamp)\n",
    "    df[column] = pd.to_datetime(df[column]).astype('int64')\n",
    "\n",
    "    # Convert fixed_min and fixed_max to timestamp\n",
    "    fixed_min_timestamped = pd.to_datetime(fixed_min).value\n",
    "    fixed_max_timestamped = pd.to_datetime(fixed_max).value\n",
    "    \n",
    "    # Normalize the column\n",
    "    df[column] = (df[column] - fixed_min_timestamped) / (fixed_max_timestamped - fixed_min_timestamped)\n",
    "    \n",
    "    # display(df[column], fixed_min_timestamped, fixed_max_timestamped)\n",
    "    \n",
    "    # Ensure that the values do not exceed the range [0, 1]\n",
    "    df[column] = df[column].clip(lower=0, upper=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Normalize and numericalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply\n",
    "\n",
    "## df_user_app_usage\n",
    "df_user_app_usage_normalized = df_user_app_usage.drop(columns=['id', 'created_at'])\n",
    "df_user_app_usage_normalized = convert_boolean_to_numeric(df_user_app_usage_normalized, 'should_be_blocked')\n",
    "df_user_app_usage_normalized = calculate_duration_and_drop_end_time(df_user_app_usage_normalized)\n",
    "df_user_app_usage_normalized = normalize_numerical_data(df_user_app_usage_normalized, 'duration', fixed_max=86400) # 24h max\n",
    "df_user_app_usage_normalized = normalize_datetimez_data(df_user_app_usage_normalized, 'start_time', fixed_min=datetime(2023, 11, 15), fixed_max=datetime.now()) # 24h max\n",
    "\n",
    "## df_user_behavior\n",
    "df_user_behavior_normalized = df_user_behavior.drop(columns=['id', 'created_at'])\n",
    "df_user_behavior_normalized = calculate_duration_and_drop_end_time(df_user_behavior_normalized)\n",
    "df_user_behavior_normalized = normalize_numerical_data(df_user_behavior_normalized, 'duration', fixed_max=86400) # 24h max\n",
    "df_user_behavior_normalized = normalize_datetimez_data(df_user_behavior_normalized, 'start_time', fixed_min=datetime(2023, 11, 15), fixed_max=datetime.now()) # 24h max\n",
    "\n",
    "# df_user_location\n",
    "df_user_location_normalized = df_user_location.drop(columns=['id', 'created_at'])\n",
    "df_user_location_normalized = convert_boolean_to_numeric(df_user_location_normalized, 'workplace')\n",
    "df_user_location_normalized = convert_boolean_to_numeric(df_user_location_normalized, 'home')\n",
    "df_user_location_normalized = calculate_duration_and_drop_end_time(df_user_location_normalized)\n",
    "df_user_location_normalized = normalize_numerical_data(df_user_location_normalized, 'duration', fixed_max=86400) # 24h max\n",
    "df_user_location_normalized = normalize_datetimez_data(df_user_location_normalized, 'start_time', fixed_min=datetime(2023, 11, 15), fixed_max=datetime.now()) # 24h max\n",
    "\n",
    "# df_users\n",
    "df_users_normalized = convert_string_to_date(df_users, 'date_of_birth')\n",
    "df_users_normalized = df_users_normalized.drop(columns=['date_of_birth', 'first_name', 'last_name'])\n",
    "df_users_normalized = normalize_numerical_data(df_users_normalized, 'age', fixed_max=130) # max-age fixed to 130 years\n",
    "\n",
    "\n",
    "# num_acceptance_categories = df__acceptance['id'].nunique()\n",
    "\n",
    "# display(num_acceptance_categories)\n",
    "\n",
    "# Check the results\n",
    "# display(df_user_app_usage_normalized.head())\n",
    "# display(df_user_app_usage_normalized.dtypes)\n",
    "\n",
    "# display(df__acceptance.head())\n",
    "# display(df__acceptance.dtypes)\n",
    "\n",
    "# display(df_user_behavior_normalized)\n",
    "# display(df_user_location_normalized)\n",
    "# display(df_users_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>app_name</th>\n",
       "      <th>start_time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>should_be_blocked</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f7427faa-c131-402a-9578-b742aaf3b5bd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176923</td>\n",
       "      <td>2</td>\n",
       "      <td>0.663409</td>\n",
       "      <td>f7427faa-c131-402a-9578-b742aaf3b5bd</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  sex       age  app_name  start_time  \\\n",
       "0  f7427faa-c131-402a-9578-b742aaf3b5bd    1  0.176923         2    0.663409   \n",
       "\n",
       "                                user_id  acceptance  should_be_blocked  \\\n",
       "0  f7427faa-c131-402a-9578-b742aaf3b5bd           4                  1   \n",
       "\n",
       "   duration  \n",
       "0  0.031204  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_user_app_usage_merged =  df_users_normalized.merge(df_user_app_usage_normalized, left_on='id', right_on='user_id')\n",
    "\n",
    "# df_user_app_usage_merged = df_user_app_usage_merged.merge(df_behavior, left_on='id', right_on='user_id', suffixes=('_location', '_behavior'))\n",
    "# df_user_app_usage_merged = df_user_app_usage_merged.merge(df_app_usage, on='user_id', suffixes=('', '_app_usage'))\n",
    "\n",
    "display(df_user_app_usage_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def transformer_model(num_unique_apps, num_unique_actions, num_numerical_features, embedding_dim):\n",
    "    # Embedding layers for categorical variables\n",
    "    app_input = tf.keras.layers.Input(shape=(None,), name='app_input')\n",
    "    app_embedding = tf.keras.layers.Embedding(input_dim=num_unique_apps + 1, output_dim=embedding_dim)(app_input)\n",
    "\n",
    "    action_input = tf.keras.layers.Input(shape=(None,), name='action_input')\n",
    "    action_embedding = tf.keras.layers.Embedding(input_dim=num_unique_actions + 1, output_dim=embedding_dim)(action_input)\n",
    "\n",
    "    # Input layer for numerical features\n",
    "    numerical_input = tf.keras.layers.Input(shape=(num_numerical_features,), name='numerical_input')\n",
    "\n",
    "    # Reshape numerical input to concatenate with embeddings\n",
    "    reshaped_numerical = tf.keras.layers.Reshape((num_numerical_features, 1))(numerical_input)\n",
    "\n",
    "    # Combining embeddings with numerical input\n",
    "    combined = tf.keras.layers.Concatenate()([app_embedding, action_embedding, reshaped_numerical])\n",
    "\n",
    "    # Transformer layer(s)\n",
    "    transformer_block = tf.keras.layers.TransformerEncoder(output_dim=embedding_dim, num_heads=2, dense_dim=embedding_dim * 2)\n",
    "    x = transformer_block(combined)\n",
    "\n",
    "    # Pooling & final Dense layers\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x) # Dropout layer for regularization\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Create and compile model\n",
    "    model = tf.keras.models.Model(inputs=[app_input, action_input, numerical_input], outputs=output)\n",
    "    model.compile(optimizer=tf.keras.layers.Adam(learning_rate=0.001), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "model = transformer_model(num_unique_apps=1000, num_unique_actions=100, num_numerical_features=2, embedding_dim=32)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(x_val, y_val)\n",
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "\n",
    "# Predicting new data\n",
    "# x_test = [app_test, action_test, numerical_test]\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Convert predictions to meaningful output\n",
    "# For binary classification, the output is a probability\n",
    "predicted_labels = [1 if p > 0.5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.pyplot.plot(history.history['accuracy'])\n",
    "plt.pyplot.plot(history.history['val_accuracy'])\n",
    "plt.pyplot.title('Model accuracy')\n",
    "plt.pyplot.ylabel('Accuracy')\n",
    "plt.pyplot.xlabel('Epoch')\n",
    "plt.pyplot.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.pyplot.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.pyplot.plot(history.history['loss'])\n",
    "plt.pyplot.plot(history.history['val_loss'])\n",
    "plt.pyplot.title('Model loss')\n",
    "plt.pyplot.ylabel('Loss')\n",
    "plt.pyplot.xlabel('Epoch')\n",
    "plt.pyplot.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.pyplot.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
